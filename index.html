<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="main.css">
    <link rel="icon" type="image/x-icon" href="assets/favicon.png">
    <title>IRASim: Learning Interactive Real-Robot Action Simulators</title>
</head>
<body>
    <div id="video_grid">
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/short/rt1.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Short Trajectory<br>RT-1<br>Prediction</div>
                <div class="overlay1 right">Short Trajectory<br>RT-1<br>Ground-truth</div>
            </div>
        </div>
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/long/rt1.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Long Trajectory<br>RT-1<br>Prediction</div>
                <div class="overlay1 right">Long Trajectory<br>RT-1<br>Ground-truth</div>
            </div>
        </div>

        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/short/bridge.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Short Trajectory<br>Bridge<br>Prediction</div>
                <div class="overlay1 right">Short Trajectory<br>Bridge<br>Ground-truth</div>
            </div>
        </div>
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/long/bridge.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Long Trajectory<br>Bridge<br>Prediction</div>
                <div class="overlay1 right">Long Trajectory<br>Bridge<br>Ground-truth</div>
            </div>
        </div>
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/short/languagetable.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Short Trajectory<br>Language-Table<br>Prediction</div>
                <div class="overlay1 right">Short Trajectory<br>Language-Table<br>Ground-truth</div>
            </div>
        </div>
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/long/languagetable.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Long Trajectory<br>Language-Table<br>Prediction</div>
                <div class="overlay1 right">Long Trajectory<br>Language-Table<br>Ground-truth</div>
            </div>
        </div>
       
    </div>
    
<div id="title_slide">
    <div class="title_left">
        <h1 style="text-align: center;">IRASim: Learning Interactive Real-Robot Action Simulators</h1>
        <div class="author-container-1">
            <div class="grid-item">NeurIPS 2024 Submission #10019</div>
        </div>

        <br>

        <div id="abstract" class="grid-container">
            <p>
                Scalable robot learning in the real world is limited by the cost and safety issues of real robots.
                In addition, rolling out robot trajectories in the real world can be time-consuming and labor-intensive.
                In this paper, we propose to learn an interactive real-robot action simulator as an alternative.
                We introduce a novel method, IRASim, which leverages the power of generative models to generate extremely realistic videos of a robot arm that executes a given action trajectory, starting from an initial given frame.
                To validate the effectiveness of our method, we create a new benchmark, IRASim Benchmark, based on three real-robot datasets and perform extensive experiments on the benchmark.
                Results show that IRASim outperforms all the baseline methods and is more preferable in human evaluations.
                We hope that IRASim can serve as an effective and scalable approach to enhance robot learning in the real world.
                To promote research for generative real-robot action simulators, we open-source code, benchmark, and checkpoints.
            </p>
        </div>
    </div>
</div>
<hr class="rounded">
<div id="overview">

    <h1 style="text-align: center;">Video Generation as Real-Robot Simulators</h1>
    <p>
        We create an interactive real-robot action simulator that can simulate robot trajectories in a way that is both accurate and almost visually indistinguishable from the real world.
        With such a simulator, agents can interactively control virtual robots to interact with diverse objects in various scenes in the simulator.
        It enables robots to improve policies by learning from simulated experiences without safety concerns and maintenance efforts.
        And the improved policy can consequently produce a large amount of simulated but realistic "real-robot" trajectories for training.
        Furthermore, the simulator can be leveraged as a dynamics model for imagining outcomes of different proposed candidate actions for model-based reinforcement learning.
    </p>

    <div class="barplot">
        <div class="image_container">
            <img src="assets/images/intro.png">
            <div class="caption" style="margin-top: 0.0vw">
                <p>Figure 1: <strong>Overview of IRASim.</strong> IRASim is an interactive real-robot action simulator that allows agents to input an action trajectory to control the "real robot" in an initial frame.</p>
            </div>
        </div>
    </div>

    <h1 style="text-align: center;">Trajectory-conditioned Video Generation</h1>

    <p>
        IRASim is a novel method that generates extremely realistic videos of a robot that executes an action trajectory, starting from a given initial frame.
        We refer to this task as the <em>trajectory-to-video</em> task.
        The trajectory-to-video task differs from the general text-to-video task. 
        While various videos can meet the text condition in the text-to-video task, the predicted video in our trajectory-to-video task must strictly and accurately follow the input trajectory.
        More importantly, a challenge of this task is that each action in the trajectory provides an exact description of the robot's movement in each frame.
        This contrasts with the text-to-video task, where textual descriptions offer a general condition without specific frame-by-frame details.
        Another challenge is that the trajectory-to-video task features rich robot-object interactions, which must adhere to physical laws.
        IRASim leverages an innovative frame-level condition method to achieve precise frame-by-frame alignment between actions and video frames. 
        We use the powerful Diffusion Transformer as the backbone of IRASim to improve the modeling of robot-object interactions. 
        <strong>IRASim can generate realistic videos of high-resolution (up to 288 Ã— 512) and long-horizon (up to 150+ frames).</strong>

    </p>

    <div class="barplot">
        <div class="image_container">
            <img src="assets/images/network.png">
            <div class="caption" style="margin-top: 0.0vw">
                <p>
                    Figure 2: <strong>Network Architecture of IRASim.</strong> (a) shows the general diffusion transformer architecture of IRASim. The input to IRASim includes the initial frame and the entire trajectory. (b) Frame-level adaptation (Frame-Ada). (c) Video-level adaptation (Video-Ada).
                </p>
            </div>
        </div>
    </div>

    <h1 style="text-align: center;">Short Trajectory Prediction</h1>
    <p>
        <strong>Uncurated</strong> qualitative results of short trajectories are shown below.
        Click the <em>Click to View More</em> button to display another random subset from 100 unpicked samples for each dataset.
        All samples are from the test set.
        Each video contains 16 frames with 4 fps. 
        The video on the left is generated by IRASim, while the video on the right is the ground truth.
    </p>
    </br>
    <div class="button-container">
        <div class="button_click" style="padding: 10px 20px; margin: -30px 20px 20px 20px;" onclick="sample_short_videos()">Click to View More</div>
    </div>
    <div id="uncurated_short_video_grid"></div>
    <br>


    <h1 style="text-align: center;">Long Trajectory Prediction</h1>
    <p>
        <strong>Uncurated</strong> qualitative results of long trajectories are shown below.
        Click the <em>Click to View More</em> button to display another random subset from 100 unpicked episodes for each dataset.
        Click the <em>Click to View Very Long Videos</em> button to display the six longest videos from the 100 unpicked episodes.
        Hover over on these longest videos to see their number of frames.
        All episodes are from the test set. 
        The average number of frames of the 100 unpicked episodes are 47.04, 36.43, and 24.57 for RT-1, Bridge, and Language-Table, respectively.
        The video on the left is generated by IRASim; the video on the right is the ground truth. 
        IRASim retains the powerful capability of generating visually realistic and accurate videos of long-horizon as in the short trajectory setting.  
    </p>
    </br>
    <div class="button-container">
        <div class="button_click" style="padding: 10px 20px; margin: -30px 20px 20px 20px;" onclick="sample_long_videos()">Click to View More</div>
        <div class="button_click_long" style="padding: 10px 20px; margin: -30px 20px 20px 20px;" onclick="sample_longest_videos()">Click to View Very Long Videos</div>
    </div>
    <div id="uncurated_long_video_grid"></div>
    <br>

    <h1 style="text-align: center;">Scaling</h1>
    <p>
        We follow DiT and train IRASim-Frame-Ada of different model sizes ranging from 33M to 679M. 
        Results are shown in Fig. 4. 
        On all three datasets, IRASim scales elegantly with the increase of model sizes and training steps. 
        This indicates strong potential for increasing model sizes and training steps to further improve the performance.
    </p>
    <div class="barplot">
        <div class="image_container">
            <img src="assets/images/scale.png">
            <div class="caption" style="margin-top: 0.0vw; margin-bottom: 0vw; text-align: center;">
                <p>
                    Figure 4: <strong>Scaling.</strong> IRASim scales elegantly with the increase of model sizes and training steps
                </p>
            </div>
        </div>
    </div>

    <h1 style="text-align: center;">
        Application
    </h1>

    <p>
        To showcase the application of IRASim, we perform experiments on controlling the "real robots" in the three datasets of IRASim Benchmark. 
        For Language-Table with a 2D translation action space, we use the arrow keys from the keyboard to input action trajectories for better accessibility.
        For RT-1 and Bridge with a 3D action space, we use the Vive controller to record action trajectories as input. 
        The videos below show that IRASim can be used as an interactive real-robot action simulator in various ways. 
        In particular, IRASim is able to robustly handle multimodality in generation. 
        The videos for Language-Table show the generation of videos with an identical initial frame but different trajectories.
    </p>

    <h2 style="text-align: center; margin: 20px 20px 20px 20px; font-weight: normal; font-size: 1.2vw">"Teleoperating" the Robot in Language-Table with a Keyboard</h2>

    <div id="app_3D_video_grid">
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/application/app_languagetable.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Language-Table <br> Prediction <br>16 frames </div>
                <div class="overlay1 right">Language-Table <br> Prediction <br>16 frames </div>
            </div>
        </div>
    </div>


    <h2 style="text-align: center; margin: 20px 20px 20px 20px; font-weight: normal; font-size: 1.2vw">"Teleoperating" the Robot in RT-1 with a Vive Controller</h2>

    <div id="app_3D_video_grid">
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/application/app_rt1.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">RT-1 <br> Prediction <br> 47 frames </div>
                <div class="overlay1 right">RT-1 <br> Ground-truth <br> 47 frames </div>
            </div>
        </div>
    </div>

    <h2 style="text-align: center; margin: 20px 20px 20px 20px; font-weight: normal; font-size: 1.2vw">"Teleoperating" the Robot in Bridge with a Vive Controller</h2>

    <div id="app_3D_video_grid">
        <div class="video_wrapper">
            <div class="video_container">
                <video autoplay muted playsinline loop>
                    <source src="assets/videos/application/app_bridge.mp4" type="video/mp4">
                </video>
                <div class="overlay1 left">Bridge <br> Prediction <br> 17 frames</div>
                <div class="overlay1 right">Bridge <br> Ground-truth <br> 17 frames</div>
            </div>
        </div>
    </div>

    
</div>
<script src="sampleVideos.js"></script>
<script>
    document.addEventListener('DOMContentLoaded', (event) => {
        sample_short_videos(); 
    });
    document.addEventListener('DOMContentLoaded', (event) => {
        sample_long_videos(); 
    });
</script>
<script type="text/javascript">
    /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
    document.querySelector('video').defaultPlaybackRate = 1.0;
    document.querySelector('video').play();

    var videos =document.querySelectorAll('video');
    for (var i=0;i<1;i++)
    {
        videos[i].playbackRate = 1.0;
    }
</script>
<script>
    /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
    var videos = document.getElementsByTagName("video");

    function checkScroll() {
        var fraction = 0.5; // Play when 70% of the player is visible.

        for(var i = 0; i < 1; i++) {  // only apply to the first video

            var video = videos[i];

            var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                b = y + h, //bottom
                visibleX, visibleY, visible;

            visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
            visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

            visible = visibleX * visibleY / (w * h);

            if (visible > fraction) {
                video.play();
            } else {
                video.pause();
            }

        }

    }
    window.addEventListener('scroll', checkScroll, false);
    window.addEventListener('resize', checkScroll, false);
</script>
<script>
    // Function to check if the user is on a mobile device
    function isMobileDevice() {
        return /Mobi|Android/i.test(navigator.userAgent);
    }

    // If the user is on a mobile device, disable autoplay
    if (isMobileDevice()) {
        const videos = document.querySelectorAll('video');
        videos.forEach(video => {
            video.autoplay = false;
        });
    }
</script>
<script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
        type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
        crossorigin="anonymous"></script>
<script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
        type="text/javascript"></script>
</body>
</html>
